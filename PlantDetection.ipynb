{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_datagen = datagen.flow_from_directory(\n",
    "    r\"E:\\New Plant Diseases Dataset\\New Plant Diseases Dataset\\train\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_datagen = datagen.flow_from_directory(\n",
    "    r\"E:\\New Plant Diseases Dataset\\New Plant Diseases Dataset\\valid\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "num_classes = 38\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r\"E:\\New Plant Diseases Dataset\\plant-224.h5\",\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, earlystop]\n",
    "\n",
    "# Train the model and save the history\n",
    "num_epochs = 5  # Change the number of epochs here\n",
    "model_history = model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_datagen.samples // 16,\n",
    "    validation_steps=val_datagen.samples // 16,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "acc_train = model_history.history['accuracy']\n",
    "acc_val = model_history.history['val_accuracy']\n",
    "epochs = range(1, len(acc_train) + 1)\n",
    "\n",
    "plt.plot(epochs, acc_train, 'g', label='Training Accuracy')\n",
    "plt.plot(epochs, acc_val, 'b', label='Validation Accuracy')\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect loss data for both training and validation\n",
    "loss_train = model_history.history['loss']\n",
    "loss_val = model_history.history['val_loss']\n",
    "\n",
    "# Check the minimum length of both arrays\n",
    "min_length = min(len(loss_train), len(loss_val))\n",
    "\n",
    "# Use the minimum length to adjust the number of epochs\n",
    "epochs = range(1, min_length + 1)\n",
    "\n",
    "plt.plot(epochs, loss_train[:min_length], 'g', label='Training Loss')\n",
    "plt.plot(epochs, loss_val[:min_length], 'b', label='Validation Loss')\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_datagen = datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\aksha\\OneDrive\\Desktop\\COLLEGE\\LW_Summer\\plant proj\\plant proj\\New Plant Diseases Dataset\\valid\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load the pre-trained model from the h5 file\n",
    "model_path = r\"C:\\Users\\aksha\\OneDrive\\Desktop\\COLLEGE\\LW_Summer\\plant proj\\plant proj\\models\\plant-224.h5\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(val_datagen)\n",
    "\n",
    "# Convert the probabilities to class labels (indices of the maximum probability)\n",
    "val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Get the true class labels\n",
    "val_true_labels = val_datagen.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(val_true_labels, val_pred_labels)\n",
    "\n",
    "# Create a confusion matrix display\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=val_datagen.class_indices.keys())\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm_display.plot(cmap='viridis', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
